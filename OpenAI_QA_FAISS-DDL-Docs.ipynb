{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "581443cd-3bf2-492c-9d44-652c4090e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60382de7-437f-4521-9a6a-5c0af2daa292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DirectoryLoader('/mnt/data/Docs_QA_AIHub', recursive='true')\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "793c2389-7da7-4f49-bff9-37279daeb228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 721 document(s) in the dataset\n",
      "There are 603 characters in the first document\n"
     ]
    }
   ],
   "source": [
    "# Get some stats about the document\n",
    "print (f'You have {len(docs)} document(s) in the dataset')\n",
    "print (f'There are {len(docs[0].page_content)} characters in the first document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e942d3-87a2-4b23-9ea8-5db321cea8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='[[tr1]] // View  json definition of a Launcher via Advanced Edit\\n\\n[[tr2]] // Edit  json definition of a Launcher via Advanced Edit\\n\\nNOTE: This feature is only available in private deployments of Domino Enterprise.\\n\\nUse the Advanced Launcher Editor to access the JSON representation of a Launcher. This is useful if you want to copy Launcher definitions between projects.\\n\\n. Go to the Launcher. ifeval::[{version} < 5.3] . Click the gear icon and then click *Edit (Advanced)*. endif::[] ifeval::[{version} >= 5.3] . Click the gear icon and then click *Edit*. . Click *Switch to JSON Edit Mode*. endif::[]', metadata={'source': '/mnt/data/Docs_QA_AIHub/content-reuse/copy-launcher-definitions.adoc'}),\n",
       " Document(page_content='To grant other users access to a project, you can add them as collaborators. To add collaborators, you must be a Contributor to the project, or the project Owner.\\n\\n[[tr5]]\\n\\n//add by user name\\n\\n[[tr6]]\\n\\n//add by email address\\n\\n\\n\\nexisting Domino user\\n\\n[[tr7]]\\n\\n//add by email address\\n\\n\\n\\nnot existing Domino user\\n\\n. In the Project, go to *Settings* > *Access & Sharing*. . In the *Collaborators and permissions* section, enter a username, email address, or organization name. + If you enter an email address for a Domino user, they will be invited to join the project as a collaborator. If you enter an email address that is not associated with an existing Domino user, they are invited to join Domino. + image:/images/4.x/screen_shot_2018-09-19_at_11.29.05_AM.png[] + . Click *Invite*. . Set the *Role* for the collaborator. + -- [[tr9]] Contributors:: Can read and write project files, and start runs. ifeval::[{version} == 5.1] On the *Settings* page, Contributors can read and write project environment variables. endif::[] ifeval::[{version} > 5.1] On the *Settings* page, Contributors can read and write project environment variables, and they can invite new collaborators. endif::[] ifeval::[{version} < 5.1] On the *Settings* page, Contributors can read and write project environment variables, and they can invite new collaborators. endif::[] ifeval::[{version} >= 4.4] Contributors can also change hardware tier and environments. endif::[] ifeval::[{version} < 4.4] Contributors cannot change hardware tiers, compute environments, or the access levels of collaborators. endif::[] [[tr10]] Results Consumers:: Can only read files and access link:71635d[published apps]. [[tr11]] Launcher Users:: Can only view and run Launchers, and see the launcher runs results. They cannot view project files. [[tr12]] Project Importers:: Can link:37158c[import the project], but otherwise cannot access it. [[tr13]] Owners:: You cannot select this role as this is the project owner. These are the only users who can archive a project, change the owner, change collaborator types, import or export to share environment variables and files between projects, or set automatic workspace shutdown times.\\n\\nSee link:26332c[Collaborator Permissions] for specific project permissions for each type of collaborator. --\\n\\n[[tr8]] . In *Notifications preference*, select how to link:ae32e7[notify] the collaborator when runs complete. This keeps your collaborators up-to-date about the work that each person is doing.', metadata={'source': '/mnt/data/Docs_QA_AIHub/content-reuse/invite-collaborators.adoc'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chunk your data up into smaller documents\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "texts = text_splitter.split_documents(docs)\n",
    "texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be89ce09-cc2c-48e7-aa51-017457d70c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 1182 documents\n"
     ]
    }
   ],
   "source": [
    "print (f'There are now {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0931124-7047-4fe8-9113-c84e07743164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your OpenAI key from the environment\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') \n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c0d06f-3daa-4c82-9e91-7db8739227c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = FAISS.from_texts([t.page_content for t in texts], embeddings)\n",
    "with open(\"faiss_doc_store.pkl\", \"wb\") as f:\n",
    "    pickle.dump(store, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18942653-32c7-4a78-ab05-db1c6b76aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index and store the embeddings locally in a pickle file\n",
    "store = FAISS.from_texts([t.page_content for t in texts], embeddings)\n",
    "with open(\"faiss_store.pkl\", \"wb\") as f:\n",
    "    pickle.dump(store, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19610f07-cf90-40f6-a1ae-0ff33e4ae015",
   "metadata": {},
   "outputs": [],
   "source": [
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ad3073-df19-4695-86ba-c61bf1256de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI assistant for answering questions about information in Domino Data Labs product documentation.\n",
    "You are given the following extracted parts of a long document and a question. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
    "If the question is not about AI or ML or data science or MLOps or related to Domino Data Lab, politely inform them that you are tuned to only answer questions about MLOps, data science and Domino Data Lab.\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown:\"\"\"\n",
    "QA_PROMPT = PromptTemplate(template=template, input_variables=[\"question\", \"context\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7acbbf1c-603d-4e18-8fe6-e8be267cfbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chain(vectorstore):\n",
    "\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), vectorstore.as_retriever(), memory=memory, qa_prompt=QA_PROMPT,\n",
    "                                                     condense_question_prompt=CONDENSE_QUESTION_PROMPT)\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba88dce2-adf5-4a9c-91f8-7d38f197ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings from the pickle file; change the location if needed\n",
    "if 'store' not in locals() or store is None:\n",
    "    with open(\"faiss_ddl_doc_store.pkl\", \"rb\") as f:\n",
    "        store = pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bab2249-6bec-411c-977a-aeebd820701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = get_chain(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7dc02fe-cd4e-4404-bd42-060328778a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is a datasource?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:\n",
      "\n",
      "A data source is a structured mechanism to create and manage connection properties to a supported external data service. Domino data sources offer a way to securely store connection properties and access data from databases, cloud storage services, and other external systems. You can create data sources directly when you need access to a specific data source that the administrator might not have set up on the deployment. To learn more about data sources, see [Domino data sources](https://docs.dominodatalab.com/fbb41f/).\n",
      "Human:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " clear_history()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " waht is a dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:\n",
      " A dataset is a collection of files that are available in user executions as a filesystem directory. These files can be used and shared as a file system directory. A Dataset always reflects the most recent version of the data. You can modify the contents of a Dataset through the Domino application or through workload executions, at any time. You can also create a Snapshot with a read-only copy of the Dataset files at a given time.\n",
      "Human:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " quit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 5574\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    while True:\n",
    "        print(\"Human:\")\n",
    "        question = input()\n",
    "        if question.lower() == \"quit()\":\n",
    "            question = None\n",
    "            break\n",
    "        if question.lower() == \"clear_history()\":\n",
    "            qa.memory.clear()\n",
    "            question = None\n",
    "            continue\n",
    "        if question is not None and question != \"\" :\n",
    "            print(\"AI:\")\n",
    "            print(qa.run(question))\n",
    "                \n",
    "print(f\"Total Tokens: {cb.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e595f-3b44-4ddf-9d06-8c7222313c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
